---
title: "Analyse factorielle discriminante"
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
author: "Paul Cascarino et Mathis Quinio-Cosquer"
date: "Décembre 2023"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Projet 2 : 

## 1. Introduction

### Les objectifs du projet
Le but de ce projet est de réduire la dimensionnalité des données de 
tweet afin de visualiser le regroupement de sentiments.


## 2. Chargement et exploration des données

### Préparation et imports
Dans un premier temps, nous effaçons la mémoire : 
```{r}
rm(list=ls())
```

Et faisons les chargements des packages nécessaires : 

```{r}
library(dplyr)
library(ggplot2)
library(stringr)

```
__Explication :__

1. `library(dplyr)` charge le package `dplyr` qui offre des fonctions
  utiles et simples dans la manipulation de données

### Chargement des données

Les données sont récupérés sur le site kaggle à l'adresse : <https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis>
Nous pouvons ainsi récupérer le csv récupéré avec : 

```{r}
df_train <- read.csv('data/twitter_training.csv', header=FALSE)
df_test <- read.csv('data/twitter_validation.csv', header=FALSE)

head(df_train)
```
__Explication :__ Les premières lignes sont des données et non le nom des colonnes
D'où le __header=FALSE__


### Analyse exploratoire des données

```{r}
dim(df_train)
dim(df_test)
```

Nous avons donc deux dataframe : 
- un de training de 74681 lignes et 4 colonnes
- un de test de 999 lignes et 4 colonnes


Ajoutons des noms aux colonnes dans nos df pour plus de simplicité: 
```{r}
names <- c('tweet_id', 'entity', 'sentiment', 'content')
colnames(df_train) <- names
colnames(df_test) <- names

colnames(df_train)
```

Nous remarquons que nous avons 2700 éléments dupliqués dans notre train_df : 
```{r}
sum(duplicated(df_train))
sum(duplicated(df_test))
```

Nous requons aussi qu'il n'y a pas d'éléments nuls
```{r}
sum(is.na(df_train))
sum(is.na(df_test))
```

#### La colonne 'entity'

```{r}
df_train$entity[23332:23334]
```
Nous avons donc les sujets des tweets en anglais. 
Ils se répètent souvent, regardons la distribution : 

```{r}
entity_dist <- factor(df_train$entity)
levels(entity_dist)
length((levels(entity_dist)))
```
Nous avons donc une liste de 32 entités, regardons la répartition
dans le dataframe d'entrainement.

```{r}
min(table(df_train$entity))
max(table(df_train$entity))

```


```
Nous remarquons que la proportion est assez similaire car elle varie uniquement
de 2244 à 2400 tweets par entités.

#### La colonne sentiments :


```{r}
sentiment_dist <- factor(df_train$sentiment)
levels(sentiment_dist)
length((levels(sentiment_dist)))
```
Nous avons donc une liste de 4 sentiments : 
"Irrelevant" "Negative"   "Neutral"    "Positive"  

Regardons la répartition des sentiments à l'aide d'un pie chart créé lors du mini projet 1 : 
```{r}
pie_chart <- function(sentiment) {
  train_df <- data.frame(
    Count = table(sentiment)
  )
  colnames(train_df) <- c('sentiment', 'Count')

  train_df <- train_df %>%
                  mutate(proportion = Count / sum(train_df$Count) * 100) %>%
                  mutate(ypos = cumsum(proportion)- 0.5*proportion)

  pie_chart <- ggplot(train_df, aes(x='', y=proportion, fill=sentiment)) +
                geom_bar(stat='identity', width=1) +
                coord_polar('y', start=0) +
                theme(legend.position='none') +
                geom_text(aes(x ='', y=ypos, label=paste(sentiment, sprintf("%.1f%%", proportion))), color='white', size = 10)

  pie_chart
}

pie_chart(sentiment_dist)

```
Nous remarquons que nous avons une répartition inégale de tweet en fonction des sentiments.
Cela sera peut être à prendre en compte pour améliorer notre modèle en fonction des poids de chacuns.

#### La colonne content : 

Regardons la répartition des longueurs des chaines de caractères en fonction des sentiments :
(Graph crée avec le mini-projet 1)
```{r}
nchar_df <- data.frame(length = nchar(df_train$content), sentiment = df_train$sentiment)

plot <- ggplot(nchar_df, aes(x=length, fill=sentiment)) +
          geom_histogram(position='identity') + 
          facet_wrap(~sentiment, scales='free')

plot
```
Nous remarquons une répartition assez similaire entre les 4 valeurs de sentiments, 
la longueur des chaînes de caractères ne permettrait donc pas d'avoir des informations utiles facilement.

### 3. Ingénierie des caractéristiques : 

#### Traitement de la colonne content

Pour cela nous allons créer une fonction qui vas : 
- mettre tous les textes en minuscule
- supprimer les chiffres
- supprimer tous les caractères spéciaux

```{r}

clean_text <- function(df_col){
  temp_col <- str_to_lower(df_col)

  # nbr_comment_false_char <- sum( ! str_detect(df$Comment, '[[:alnum:]]') == TRUE)
  # nbr_comment_num <- sum(str_detect(df$Comment, '^[0-9]') == TRUE)
  # nbr_comment_with_punct <- sum(str_detect(df$Comment, '[[:punct:]]') == TRUE)
  return(temp_col)
}

df_train$content <- clean_text(df_train$content)
df_test$content <- clean_text(df_test$content)

head(df_train$content)  
```

