---
title: "Analyse factorielle discriminante"
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
author: "Paul Cascarino et Mathis Quinio-Cosquer"
date: "Décembre 2023"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Projet 2 : 

## 1. Introduction

### Les objectifs du projet
Le but de ce projet est de réduire la dimensionnalité des données de 
tweet afin de visualiser le regroupement de sentiments.


## 2. Chargement et exploration des données

### Préparation et imports
Dans un premier temps, nous effaçons la mémoire : 
```{r}
rm(list=ls())
```

Et faisons les chargements des packages nécessaires : 

```{r}
library(dplyr)
library(ggplot2)

```
__Explication :__

1. `library(dplyr)` charge le package `dplyr` qui offre des fonctions
  utiles et simples dans la manipulation de données

### Chargement des données

Les données sont récupérés sur le site kaggle à l'adresse : <https://www.kaggle.com/datasets/jp797498e/twitter-entity-sentiment-analysis>
Nous pouvons ainsi récupérer le csv récupéré avec : 

```{r}
df_train <- read.csv('data/twitter_training.csv', header=FALSE)
df_test <- read.csv('data/twitter_validation.csv', header=FALSE)

head(df_train)
```
__Explication :__ Les premières lignes sont des données et non le nom des colonnes
D'où le __header=FALSE__


### Analyse exploratoire des données

```{r}
dim(df_train)
dim(df_test)
```

Nous avons donc deux dataframe : 
- un de training de 74681 lignes et 4 colonnes
- un de test de 999 lignes et 4 colonnes


Ajoutons des noms aux colonnes dans nos df pour plus de simplicité: 
```{r}
names <- c('tweet_id', 'entity', 'sentiment', 'content')
colnames(df_train) <- names
colnames(df_test) <- names

colnames(df_train)
```

Nous remarquons que nous avons 2700 éléments dupliqués dans notre train_df : 
```{r}
sum(duplicated(df_train))
sum(duplicated(df_test))
```

Nous requons aussi qu'il n'y a pas d'éléments nuls
```{r}
sum(is.na(df_train))
sum(is.na(df_test))
```

#### Regardons la colonne 'entity'

```{r}
df_train$entity[23332:23334]
```
Nous avons donc les sujets des tweets en anglais. 
Ils se répètent souvent, regardons la distribution : 

```{r}
entity_dist <- factor(df_train$entity)
levels(entity_dist)
length((levels(entity_dist)))
```
Nous avons donc une liste de 32 entités, regardons la répartition
dans le dataframe d'entrainement.

Créons un graphique qui rend plus visuel la répartition des émotions : 
```{r}
pie_chart <- function(entity) {
  train_df <- data.frame(
    Count = table(entity)
  )
  colnames(train_df) <- c('Entity', 'Count')

  train_df <- train_df %>%
                  mutate(proportion = Count / sum(train_df$Count) * 100) %>%
                  mutate(ypos = cumsum(proportion)- 0.5*proportion)

  pie_chart <- ggplot(train_df, aes(x='', y=proportion, fill=Entity)) +
                geom_bar(stat='identity', width=1) +
                coord_polar('y', start=0) +
                theme(legend.position='none') +
                geom_text(aes(x ='', y=ypos, label=Entity), color='white', size = 10)

  pie_chart
}

pie_chart(entity_dist)

```
Nous remarquons que la proportion est assez similire entre les entités,
Il n'y en a pas qui prennent vraiment le dessus.
