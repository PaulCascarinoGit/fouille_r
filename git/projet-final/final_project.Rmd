---
title: "<FONT color='#0066CC'><FONT size = 4 ><DIV align= center> AP-4209 ESIEE-Paris: 2023 -2024 </DIV></FONT></FONT>"
output:
  html_document:
    highlight: textmate
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
---


<style type="text/css">
body, td {font-size: 15px;}
code.r{font-size: 5px;}
pre { font-size: 12px;}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"}
Fouille de données avec R pour la data science et l'intelligence artificielle\

Projet final : Classification bayésienne et Analyse Factorielle Discriminante 
:::

</FONT></FONT>


<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"}
 1. Chargement et exploration des données
:::

</FONT></FONT>

# Installation des librairies


```{r}
install.packages("tm")
install.packages("dplyr")
install.packages("Matrix")
```

# Chargement des librairies
```{r}
library(tm)
library(dplyr)
library(Matrix)
```

# Chargement des données
```{r}
# Charger les données
data <- read.csv("train_essays.csv", header = FALSE)
```


```{r}
#Les premières lignes des données :
head(data)
```

```{r}
colnames(data) <- c("id", "prompt_id", "text", "generated")
head(data)
```

```{r}
#Résumé statistique des données :
summary(data)
```

```{r}
#Distribution des classes :
#table(data$id)
#table(data$prompt_id)
#table(data$text)
table(data$generated)
```


```{r}
# Textes générés (=1)
generated_texts <- data[data$generated == 1, ]

print(head(generated_texts$text))
```

# Prétraitement du texte
```{r}
corpus <- Corpus(VectorSource(data$text))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
print(corpus)
```

# Analyse exploratoire du texte

```{r}

# Créer la DTM
dtm <- DocumentTermMatrix(corpus)

# Examinez quelques-uns des éléments de la DTM
inspect(dtm[1:5, 1:10]) 
```

```{r}
# Longueur des textes
text_lengths <- sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " "))))
hist(text_lengths, main="Histogramme de la longueur des textes", xlab="Nombre de mots", col="skyblue", border="black")
```

```{r}
# Distribution de la classe en fonction de la longueur des textes
data$text_lengths <- text_lengths
cat("\nDistribution de la classe en fonction de la longueur des textes :\n")
summary(data %>% group_by(generated) %>% summarise(avg_length = mean(text_lengths)))
```



::: {align="center"}
 2. Extraction de caractéristiques (Feature Extraction)
:::


```{r}
# Distribution de n-grammes
ngram_dist <- rowSums(as.matrix(dtm))
```

```{r}
# Variabilité de la longueur des phrases
text_lengths <- sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " "))))
sentence_variability <- apply(matrix(text_lengths, ncol = 1), 1, sd)
```

```{r}
install.packages("quanteda")

```
```{r}
library(quanteda)#traitement de texte (lisibilité)
```

```{r}
# Scores de lisibilité avec le package quanteda
readability_scores <- textstat_readability(data$text)
```

```{r}
# Créer un tableau avec les caractéristiques
features <- data.frame(
  ngram_dist,
  sentence_variability,
  readability_scores
)

# Afficher les premières lignes du tableau de caractéristiques
head(features)
```


```{r}
install.packages(tidyr)
```

```{r}
library(tidyr)
```

```{r}
# Calculer TF-IDF
tfidf <- weightTfIdf(dtm)

# Afficher les termes
terms <- colnames(tfidf)

# Sélectionner quelques documents pour inspection
sample_docs <- sample(1:ncol(tfidf), 5)
sample_tfidf <- tfidf[, sample_docs]

# Afficher les premières lignes du tableau de caractéristiques
print(as.data.frame(as.matrix(sample_tfidf)))
```

```{r}
install.packages("bert")
```

```{r}
library(bert)
```


::: {align="center"}
 3. Analyse factorielle discriminante (Réduction de la dimensionnalité)
:::

```{r}
install.packages("MASS")
```

```{r}
library(MASS)
```

```{r}
install.packages("caret")
```

```{r}
library(caret)
```


```{r}
data <- read.csv("train_essays.csv", header = FALSE)

colnames(data) <- c("id", "prompt_id", "text", "generated")
```


```{r}
# Séparation des données en ensemble d'entraînement et de test
set.seed(123)
train_indices <- sample(1:nrow(data), 0.8 * nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

```{r}
# Identifier les variables constantes
constant_cols <- nearZeroVar(train_data)
```

```{r}
# Vérifier le nouvel équilibre des classes
table(under_sampled_train_data$generated)
```

```{r}
# Sélectionner les variables qui ne sont pas constantes
train_data_selected <- train_data[, !constant_cols]
```

```{r}
# Vérifier si la variable réponse est toujours présente
print("generated" %in% colnames(train_data_selected))
```

```{r}

lda_model <- lda(generated ~ ., data = train_data_clean)
```


```{r}
lda_train <- predict(lda_model, train_data)$x
lda_test <- predict(lda_model, test_data)$x
```

```{r}
# Vérification des dimensions des résultats
dim(lda_train)
dim(lda_test)
```

```{r}
# Afficher les noms de colonnes dans train_data
print(colnames(train_data))

# Afficher les premières lignes des colonnes problématiques
head(train_data[, c(1102, 1104, 1892), drop = FALSE])

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

