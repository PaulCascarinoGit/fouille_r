---
title: "<FONT color='#0066CC'><FONT size = 4 ><DIV align= center> AP-4209 ESIEE-Paris: 2023 -2024 </DIV></FONT></FONT>"
output:
  html_document:
    highlight: textmate
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
---


<style type="text/css">
body, td {font-size: 15px;}
code.r{font-size: 5px;}
pre { font-size: 12px;}
</style>


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```




<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"}
Fouille de données avec R pour la data science et l'intelligence artificielle\

Projet final : Classification bayésienne et Analyse Factorielle Discriminante 
:::

</FONT></FONT>


<FONT color='#0066CC'><FONT size = 4 >

::: {align="center"}
 1. Chargement et exploration des données
:::

</FONT></FONT>

# Installation des librairies


```{r}
install.packages("tm")
install.packages("dplyr")
install.packages("Matrix")
install.packages("bert")
install.packages("quanteda.textstats")
install.packages("MASS")
install.packages("caret")
install.packages("skimr")
```

# Chargement des librairies
```{r}
library(tm)
library(dplyr)
library(Matrix)
library(bert)
library(quanteda.textstats)#traitement de texte (lisibilité)
library(MASS)
library(caret)
library(skimr)
```

# Chargement des données
```{r}
# Charger les données
train_essays <- read.csv("train_essays.csv")
train_prompts <- read.csv("train_prompts.csv")
```


```{r}
#Les premières lignes des données :
head(train_essays)
```
```{r}
head(train_prompts)
```

```{r}
data <- merge(train_prompts, train_essays, by = 'prompt_id', all = TRUE)
data <- na.omit(data)
head(data)
```

```{r}
#Résumé statistique des données :
summary(data$generated)
```

```{r}
#Distribution des classes :
#table(data$id)
#table(data$prompt_id)
#table(data$text)
table(data$generated)
```

```{r}
# Textes générés (=1)
generated_texts <- data[data$generated == 1, ]

print(head(generated_texts$text))
```

```{r}
# Tableau de fréquences pour generated
freq_table <- table(train_essays$generated)

# Afficher le tableau de fréquences
print(freq_table)

# Créer un graphique à barres
barplot(freq_table, main = "Distribution de 'generated'", xlab = "generated", ylab = "Fréquence")
```

```{r}
data %>%
  skim()

sum(data$generated)
```

# Prétraitement du texte
```{r}
corpus <- Corpus(VectorSource(data$text))
corpus <- tm_map(corpus, content_transformer(tolower))
corpus <- tm_map(corpus, removePunctuation)
corpus <- tm_map(corpus, removeNumbers)
corpus <- tm_map(corpus, removeWords, stopwords("english"))
corpus <- tm_map(corpus, stripWhitespace)
print(corpus)
```

# Analyse exploratoire du texte

```{r}

# Créer la DTM
dtm <- DocumentTermMatrix(corpus)

# Examinez quelques-uns des éléments de la DTM
inspect(dtm[1:5, 1:10]) 
```


```{r}
# Longueur des textes
text_lengths <- sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " "))))
hist(text_lengths, main="Histogramme de la longueur des textes", xlab="Nombre de mots", col="skyblue", border="black")
```

```{r}
# Distribution de la classe en fonction de la longueur des textes
data$text_lengths <- text_lengths
cat("\nDistribution de la classe en fonction de la longueur des textes :\n")
summary(data %>% group_by(generated) %>% summarise(avg_length = mean(text_lengths)))
```



::: {align="center"}
 2. Extraction de caractéristiques (Feature Extraction)
:::


```{r}
# Distribution de n-grammes
ngram_dist <- rowSums(as.matrix(dtm))
```

```{r}
# Variabilité de la longueur des phrases
text_lengths <- sapply(corpus, function(x) length(unlist(strsplit(as.character(x), " "))))
sentence_variability <- apply(matrix(text_lengths, ncol = 1), 1, sd)
```

```{r}
# Scores de lisibilité avec le package quanteda
readability_scores <- textstat_readability(data$text)
```

```{r}
# Créer un tableau avec les caractéristiques
features <- data.frame(
  ngram_dist,
  sentence_variability,
  readability_scores
)

# Afficher les premières lignes du tableau de caractéristiques
head(features)
```

```{r}
# Convertion en facteur
#data$instructions <- as.factor(data$instructions)
#data$source_text <- as.factor(data$source_text)
#data$id <- as.factor(data$id)
#data$text <- as.factor(data$text)
```

```{r}
# Conversions en int
#data$instructions <- as.integer(data$instructions)
#data$source_text <- as.integer(data$source_text)
#data$id <- as.integer(data$id)
#data$text <- as.integer(data$text)
```
# TF-IDF

```{r}
# Calculer TF-IDF
tfidf <- weightTfIdf(dtm)

# Afficher les termes
terms <- colnames(tfidf)

# Sélectionner quelques documents pour inspection
sample_docs <- sample(1:ncol(tfidf), 5)
sample_tfidf <- tfidf[, sample_docs]

# Afficher les premières lignes du tableau de caractéristiques
print(as.data.frame(as.matrix(sample_tfidf)))
```


::: {align="center"}
 3. Analyse factorielle discriminante (Réduction de la dimensionnalité)
:::

```{r}
# Séparation des données en ensemble d'entraînement et de test
set.seed(123)
train_indices <- sample(1:nrow(data), 0.8 * nrow(data))
train_data <- data[train_indices, ]
test_data <- data[-train_indices, ]
```

```{r}
print(colnames(train_data))
```

```{r}
# Convertir la colonne "generated" en facteur
train_data$generated <- as.factor(train_data$generated)
```

```{r}

```


```{r}
# Appliquer l'analyse discriminante
lda_model <- lda(text ~ ., data = train_data)
```


```{r}
# Appliquer le modèle aux ensembles d'entraînement et de test
lda_train <- predict(lda_model, under_sampled_train_data)$x
lda_test <- predict(lda_model, test_data)$x
```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

