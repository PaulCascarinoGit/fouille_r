```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
install.packages("dplyr")
install.packages("skimr")
install.packages("janitor")
install.packages("ggplot2")
install.packages("tm")
install.packages("xgboost")
install.packages("pROC")
install.packages("caret")
```

```{r}
library(dplyr)
library(skimr)
library(janitor)
library(ggplot2)
library(tm)
library(xgboost)
library(pROC)
library(caret)
```

```{r}
train_essays <- read.csv("train_essays.csv")
train_prompts <- read.csv("train_prompts.csv")
```

```{r}
### now lets prep for r formatting of the fields
train_essays <- clean_names(train_essays)
train_prompts <- clean_names(train_prompts)
```

```{r}
head(train_essays)
```
```{r}
head(train_prompts)
```
```{r}
summary(train_essays$generated)
```

```{r}
### generated by Prompt ID
train_essays %>%
  ggplot(aes(generated)) +
  geom_bar() +
  facet_wrap(~prompt_id) +
  labs(title = 'Generated by Prompt ID')
```

```{r}
##Prompt ID by Generated
train_essays %>%
  ggplot(aes(prompt_id)) +
  geom_bar() +
  facet_wrap(~generated) +
  labs(title = 'Prompt by Generated')
```

```{r}
## so lets join the tables
data <- full_join(train_prompts, train_essays, by = 'prompt_id')
```

```{r}
head(data)
```


```{r}
## there doesn't appear to be any duplicate text entries.
## skim the data
data %>%
  skim()

sum(data$generated)
```


```{r}
## the id of the essay is more of a factor and way to categorize
## 

data$instructions <- as.factor(data$instructions)
data$source_text <- as.factor(data$source_text)
data$id <- as.factor(data$id)
data$text <- as.factor(data$text)
```

```{r}
## then convert to int.
data$instructions <- as.integer(data$instructions)
data$source_text <- as.integer(data$source_text)
data$id <- as.integer(data$id)
data$text <- as.integer(data$text)
```

```{r}
train_x = data.matrix(data[, -6])
length(train_x)
```

```{r}
train_y = data[,6]
length(train_y)
```

```{r}
# set up the matrix for train and test to work with XGBoost
xgb_train = xgb.DMatrix(data = train_x, label = train_y)
```

```{r}
watchlist = list(train=xgb_train)
```

```{r}
set.seed(3333)
model = xgb.train(data = xgb_train,
                  max.depth = 3,
                  watchlist = watchlist,
                  nrounds = 100)
```

```{r}
## now for importance
importance_matrix = xgb.importance(colnames(xgb_train), model = model)

##determine measurements
importance_matrix
```

```{r}
## graph
xgb.plot.importance(importance_matrix[1:10],)
```

```{r}
###and for prediction####

params <- list(
  booster = 'gbtree',
  objective = 'binary:logistic',
  eta = .3,
  gamma = 0,
  max_depth = 2,
  eval_metric = 'auc',
  min_child_weight =1,
  subsample = 1,
  colsample_bytree = 1,
  prediction = TRUE
)
```

```{r}
###cross validation

xgbcv <- xgb.cv(
  params = params,
  data = train_x,
  label = train_y,
  prediction = TRUE,
  nrounds = 100,
  nfold = 2,
  showsd = TRUE,
  stratified = TRUE,
  early_stopping_rounds = 20,
  maximize = FALSE
)
```

```{r}
## best iteration

it = which.max(xgbcv$evaluation_log$test_auc_mean)
best.iter = xgbcv$evaluation_log$iter[it]
```

```{r}
## plot the accuracy over each iteration ###

plot(pROC::roc(
  response = train_y,
  predictor = xgbcv$pred,
  levels = c(0,1)),
  lwd = 1.5
)
```



```{r}
## confusion matrix ####
train_y <- as.factor(train_y)
prediction <- as.factor(ifelse(xgbcv$pred <= 0.5, 0, 1))
```

```{r}
options(scipen = 999) ## ensure that data is readable, not the e-numbering system
```

```{r}
confusionMatrix(prediction, train_y)
```