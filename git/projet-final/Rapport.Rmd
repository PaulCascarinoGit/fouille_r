---
title: "Projet final : Classification bayésienne et Analyse Factorielle Discriminante "
output:
  html_document:
    theme: readable
    toc: yes
    toc_depth: 6
    toc_float: yes
author: "Paul Cascarino et Mathis Quinio-Cosquer"
date: "Février 2023"
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Classification bayésienne et Analyse Factorielle Discriminante 

## 1. Préambule

### Contexte 

De nos jours, il y a une forte montée des IA capable de comprendre ainsi que de créer du langage humain.
Ces IA sont appelés __Large Language Models (LLM)__ et sont très récemment démocratisé par
l'apparition brusque de Chat gpt et de nombreux autres.

Ces IA sont capable de générer du texte, il est difficile pour un humain de savoir si le texte est fait par une IA ou non.

Dans ce projet, nous nous intéresseront à savoir si une machine serait capable de détecter cela.


### Les objectifs de ce projet

Les objectifs de ce proet sont donc de développer un système de classification
qui utilise des __méthodes bayésienne__ ainsi que des caractéristiques extraintes par 
l'__analyse factorielle discriminante (AFD)__

Dans le but de faire la distinction entre le texte généré par l'IA et par l'Homme


## 2. Données et prétraitements

### Description du jeu de données 

#### Préparation et imports 

Dans un premier temps, nous effaçons la mémoire : 
```{r}
rm(list=ls())
```

Et faisons les chargements des packages nécessaires :

```{r}
library(ggplot2)
library(dplyr)
library(stringr)

# Permet la tokenization : https://smltar.com/tokenization#types-of-tokens 
library(tokenizers)

# Permet l'utilisation de liste pour le stop-words : https://smltar.com/stopwords#premadestopwords
library(stopwords)

# Permet la stemmatization : https://smltar.com/stemming#how-to-stem-text-in-r
library(SnowballC)

```
__Explication :__

3. `library(ggplot2)` charge le package `ggplot2` qui permet de créer 
  facilement des graphiques en R
4. `library(dplyr)` charge le package `dplyr` qui offre des fonctions
  utiles et simples dans la manipulation de données
5. `library(stringr)` charge le package `stringr` qui offre des fonctions
  utiles dans la manipulation des chaînes de caractères

#### Chargement des données

Les données sont récupérés sur le site kaggle à l'adresse : <https://www.kaggle.com/competitions/llm-detect-ai-generated-text>
Nous pouvons ainsi récupérer le csv récupéré avec : 
```{r}
path_essays <- 'datasets/llm-detect-ai-generated-text/train_essays.csv'
path_prompts <- 'datasets/llm-detect-ai-generated-text/train_prompts.csv'

df_essays <- read.csv(path_essays)
#df_prompts <- read.csv(path_prompts)

```

#### Description d essays : 

Voici un aperçu de nos données : 

Nous avons un dataframe __d'essays__ qui sont soit écrits par des humains
soit générés par des LLM : 
```{r}
df_essays[1,]
```

Regradons ses colonnes :
```{r}
colnames(df_essays)
```

Nous avons : 

- "id" : qui est l'unique ID pour chaque essay       

- "prompt_id" : permet d'identifier le prompt de l'essay

- "text" : le texte de l'essay    

- "generated" : 0 si généré par Homme 1 si non 

Dans l'exemple ci dessus (la première ligne), nous avons un texte écris en anglais 
par un homme (generated  = 0)

```{r}
dim(df_essays)
```
Nous avons une liste de 1378 essays et donc de 4 colonnes cités ci-dessus

```{r}
summary(df_essays)
```

Nous remarquons que : 

- "id" : contient des caractères       

- "prompt_id" : a un min à 0.0000 et a un max à 1.0000

- "text" : le texte de l'essay    

- "generated" :  a une moyenne de 0.002177 ce qui signifierait plus
  essays générés par l'Homme (0)


Nous remarquons qu'il n'y a pas d'éléments dupliqués : 
```{r}
sum(duplicated(df_essays))
```

Nous remarquons aussi qu'il n'y a pas d'éléments nuls
```{r}
sum(is.na(df_essays))
```

Regarsons maintenant notre colonne text : 

```{r}
df_essays$text[500]
```
Nous avons de long textes écrits en anglais avec des sauts de ligne (\n) et de la ponctuation.

Regardons la répartition de la longueur des textes : 
```{r}
nchar_df <- data.frame(length = nchar(df_essays$text))
nchar_df$generated <- df_essays$generated

plot <- ggplot(nchar_df, aes(x = length, fill = factor(generated))) + geom_histogram()

plot
```
Nous remarquons que nous avons des textes de longueurs très variables.
La distribution des longueurs des textes semble ne pas donner beaucoup d'information 
autre que nes ne disposons probablement pas de textes de longueur abbérantes

Regardons la répartition des textes écrits pas les humains ou IA :
```{r}
df_essays$generated <- factor(df_essays$generated)
levels(df_essays$generated)
```
nous avons donc bien 2 levels 0 pour Homme et 1 pour IA

Créons un graphique qui rend plus visuel la répartition des émotions : 
```{r}
pie_chart <- function(generated_col) {
  generated <- data.frame(
    generated = generated_col
  )
  
  generated <- generated %>%
                  count(generated) %>%
                  mutate(proportion = n / sum(n) * 100) %>%
                  mutate(ypos = cumsum(proportion) - 0.5 * proportion)

  pie_chart <- ggplot(generated, aes(x = '', y = proportion, fill = generated)) +
                geom_bar(stat = 'identity', width = 1) +
                coord_polar('y', start = 0) +
                theme(legend.position = 'none') +
                geom_text(aes(x = '', y = ypos, label = paste0(generated, ": ", round(proportion, 1), "%")), color = 'white', size = 3)

  return(pie_chart)
}

# Exécuter la fonction avec la colonne generated
pie_chart(df_essays$generated)

```
Nous remarquons l'immense majorité des textes que nous avons sont écrits par des humains

```{r}
nchar_df <- data.frame(length = nchar(df_essays$text))
nchar_df$generated <- df_essays$generated

plot <- ggplot(nchar_df, aes(x = length, fill = factor(generated))) + geom_histogram()

plot
```
Cependant nous nous rendons bien compte que les textes écrits par des humains sont bien 
plus long que ceux écrits par des IA. La longueur du texte est peut être une feature à prendre en compte.

```{r}
df_generated_1 <- subset(df_essays, generated == 1)
dim(df_generated_1)
```

Nous n'avons que très peu de texts écrits pas l'IA dans notre dataframe.
Cela peut poser problème et donc les idées émises précédemment ne sont pas à prendre en compte
#### Description des prompts : 

Notre dataframe de promt nous permets de voir les promts données aux 
Hommes ou LLM qui on donnés lieux aux essay.

Les 2 sont liés par le "prompt_id".

```{r}
colnames(df_prompts)
```
Nous avons : 

- "prompt_id" : qui est unique pour chaque prompt

- "prompt_name" : Le titre du prompt

- "instructions" : Les instructions données aux étudiants (Humains)

- "source_text" : La source (articles) des essays pour répondre aux prompts

```{r}
dim(df_prompts)
```
### Etapes de prétraitements


## 3. Extraction de caractéristiques (Feature Extraction)

### Caractéristiques linguistiques et stylométriques

### Technique de vectorisation utilisée

Discutez de la technique de vectorisation utilisée

## 4. Analyse des facteurs discriminants

### Explication de l AFD

Explication de l AFD, y compris les fondements mathématiques et l application à 
l’ensemble de données

## 5. Classification bayésienne

Élaborer sur la méthodologie de classification bayésienne utilisée, y compris les 
techniques avancées

## 6. Evaluation et résultats

Discutez des mesures d évaluation du modèle et du processus de validation.

## 7. Conclusion

Résumer les principales constatations et conclusions tirées de l analyse

## 8. Travaux futurs

Mettez en évidence les domaines nécessitant des recherches plus approfondies, tels que 
l amélioration du modèle ou l exploration de fonctionnalités alternatives. 